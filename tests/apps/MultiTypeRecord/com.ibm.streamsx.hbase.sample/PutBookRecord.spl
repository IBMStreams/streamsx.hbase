
/* Copyright (C) 2014, International Business Machines Corporation  */
/* All Rights Reserved                                	                 */
namespace com.ibm.streamsx.hbase.sample ;

use com.ibm.streamsx.hbase::HBASEPut ;

/**
 * Read the contents of a file into a blob.
 */
stateful blob getFileContents(rstring filename)
{
	mutable int32 error = 0 ;
	rstring absFile = dataDirectory()+"/"+filename;	
	appTrc(Trace.info,"Absolute path for file "+filename+" is "+absFile);
	uint64 file = spl.file::fopen(absFile, "r", error) ;
	assert(error == 0,"File "+filename+" (absolute path: "+absFile+") failed to open with code "+(rstring)error) ;
	mutable blob toReturn = [ ] ;
	spl.file::freadfile(toReturn, file, error) ;
	assert(error == 0,"File "+filename+" (absolute path: "+absFile+") could not be read, error code "+(rstring)error) ;
	spl.file::fclose(file,error);
	return toReturn ;
}

/**
 * Put a record representing a book into HBASE.
 * 
 * Reads a file with the book metadata, including title, author, year, and
 * the filename containing the first chapter.
 * 
 * Then, converts that to a tuple with a title, author, year, and a spl blob
 * actually containing the entire first chapter.
 * 
 * It then puts that tuple into HBASE.  
 * 
 * It's output stream is a sorted version of the tuples placed in HBASE.  This is useful
 * for HBASEScan and HBASEGet verification.
 */
composite PutBookRecord(output checkStream )
{
	param expression<rstring> $tableName: "streamsSample_recordWithTypes" ;
	graph
	// read the book data.
		stream<rstring title, ustring author, int64 year, rstring firstChapterFile>
			bookDetails = FileSource()
		{
			param
				file : "books.csv" ;
		}

		// Change format, get the contents of the file into the the tuple
		stream<rstring key, tuple<rstring title, ustring author, int64 year,
			blob firstChapter> book> putStream = Functor(bookDetails)
		{
			output
				putStream : key = title + "|" +(rstring) year, book =
				{
					title = title, author = author, year = year, firstChapter =
						getFileContents(firstChapterFile)
				} ;
		}

		// sort the stream going into HBASE--that way verifying agains the results
		// of HBASE scan is a little easier.
		stream<rstring key, tuple<rstring title, ustring author, int64 year,
			blob firstChapter> book> checkStream = Sort(putStream)
		{
			window
				putStream : tumbling, punct() ;
			param
				sortBy : key ;
		}

		// Now we put stuff into HBASE
		() as PutSink = HBASEPut(putStream)
		{
			param
				tableName : $tableName ;
				valueAttrName : "book" ;
				rowAttrName : "key" ;
				staticColumnFamily : "all" ;
		}

}
